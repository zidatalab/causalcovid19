# Data

We collected and aggregated data on reported COVID-19 cases, regional socio-demographic factors, weather, and general mobility on district and state level in Germany for the period of 15 February 2020 to 8 July 2020. Our observation period for the outcome consisted of all dates from 23 February 2020 to 8 July 2020 ($T=137$), since we used a lag of 8 days for all confounders. We did not exclude any states or districts ($K=401$). We analyzed the daily reported number of new cases as outcome ($K\cdot T=54{\ }937$ observations). The set of possible predictors was derived from our causal DAG (see Table \@ref(tab:model-vars) and Figure \@ref(fig:dag-covid-19)). Due to modelling and data limitations, some of the predictors were unobserved or were modelled as a construct consisting of several variables. For our causal analysis, we computed adjustment sets in three different scenarios for separate exposures within the DAG: i) mobility of population, ii) awareness of COVID-19 (i.e. Google searches for "corona"), iii) weather (i.e. temperature).

## Variables

We downloaded German daily case numbers on district level reported by Robert Koch Institute (RKI, [@casenumbers_rki], acquired on 12 July 2020) and aggregated them by date. The number of daily active cases for day $d$ was derived by subtracting the total number of reported cases on day $d$ and day $d-14$ (14 days as a conservative estimate for the infectious period, which corresponds here to the required quarantine time in Germany).

To assess the mobility of the German population, we used data publicly available on German state level from Google [@google_mobility]. Measurements are daily relative changes of mobility in percent compared to the period of 3 January 2020 to 6 February 2020. Missing values ($25$ out of $13{\ }488$) were imputed with value $0$ and the state level measurements were passed onto districts within the corresponding state. Google mobility data was available for six different sectors of daily life ("retail and recreation", "grocery and pharmacy", "parks", "transit stations", "workplaces", "residential") which means that "mobility" is a construct consisting of several variables. All variables but "residential" mobility are relative changes of daily visitor numbers to the corresponding sectors compared to the reference period. "Residential" mobility is the relative change of daily time spent at residential areas.

The notion of awareness in the population of COVID-19 describes the general state of alertness about the new infectious disease. As such, it was hard to measure directly. As a proxy, we used the relative interest in the topic term "corona" as indicated by Google searches. The daily data was available on state level [@google_trends] and passed onto district level. As a second proxy for awareness, we used the daily reported number of COVID-19 cases on the day of the exposure: Since media reported case numbers prominently, we assumed that this could reflect individual awareness, too.

We constructed daily weather from four variables ("temperature", "rainfall", "humidity", "wind"). Weather data was downloaded from Deutscher Wetterdienst (DWD, [@dwd_weather]) for all weather stations in Germany below 1000 meters altitude with daily records in 2020 until 8 July 2020. District level daily weather data was aggregated per district by averaging the data from the three nearest weather stations (which includes weather stations inside the district). Missing values were imputed with mean values ($n=59$ for wind).

The reported number of COVID-19 cases varied strongly by day of the week. Thus, we included "weekday" as a categorical variable. Similarly, the reported cases and the exposure to the virus were affected by official holidays. Within the observation period, this included among others Good Friday, Easter Monday, and Labor Day. To correct for effects of these days, we included two variables in the model, "Holiday (report)" (indicates if the day of the report was a holiday, because governmental health departments were less likely to be on full duty) and "Holiday (exposure)" (indicates if the day of exposure to the virus was a holiday, because the population behaves differently on holidays).

For different official and political measures we used one-hot encoded daily variables, i.e. ban of mass gatherings, school and kindergarten closures and their gradual reopening, contact restrictions, and mandatory face masks for shopping and public transport.

We included several social, economic, and demographic factors on the district level with direct or indirect influence on the risk of exposure to SARS-CoV-2 in our analysis. All are readily available from INKAR database [@inkar]. We used the share of population that is 65 years or older and the share of population that is younger than 18 years (Age), the share of females in population (Gender), the population density, the share of foreign citizenships and the share of the population seeking refuge (Foreign citizenship), the share of low-income households (Socio-economic status), voter turnout, share of right-wing populist party votes, and the number of nursing (retirement) homes.

<!-- next lines are for proper display of sources/references in table -->

(ref:googlemobility) Google [@google_mobility]

(ref:dwdweather) DWD [@dwd_weather]

(ref:postfacemasks) IZA [@mitze2020face]

(ref:inkar) INKAR [@inkar]

(ref:googletrends) Google [@google_trends]

(ref:rki) RKI [@casenumbers_rki]

```{r model-vars, echo=FALSE, message=FALSE, warning=FALSE}
library("dplyr")
library("readr")
library("knitr")
library("kableExtra")
my_variables <- read_delim("tables/t_variables.csv", delim=";") %>%
  filter(observed!="unobs") %>%
  dplyr::select(-contains("missing"), -contains("observ"))
options(knitr.kable.NA = '-')
kable(my_variables, caption = "Observed model variables", # landscape(
                booktabs = TRUE,  format = "latex") %>% # 
  kable_styling(font_size = 6, full_width = FALSE) %>%
  pack_rows("Mobility", 4, 9) %>%
  pack_rows("Weather", 10, 13) %>%
  pack_rows("Policies", 14, 17) %>%
  pack_rows("Socio-demographic", 18, 25) %>%
  pack_rows("Awareness", 26, 27) %>%
  pack_rows("Case numbers", 28, 29) %>%
  # pack_rows("Unobserved", 31, 36) %>%
  column_spec(5, width = "10em") # 
# , margin="1cm")
```

All variables but the outcome "Reported new cases of COVID-19" and the offset "Active cases" were centered for numerical stability. We did not scale variables to unit variance to maintain interpretability of effects on the original scale of variables. Additionally, we lagged the effect of all variables (but outcome, offset, and the non-dynamic socio-demographic variables) by 8 days (see Section \@ref(results)) which means that we assumed that their effects on the outcome will be visible after 8 days.

# Methods

## Causal analysis with DAG and adjustment sets

We used a directed acyclic graph as a graphical representation of the hypothesized causal reasoning that leads to exposure to the SARS-CoV-2 virus, onset of COVID-19, and finally reports of COVID-19 cases. Every node $v_i$ in the graph is the graphical representation of an observed or unobserved variable $x_i$, a directed edge $e_{ij}$ is an arrow from node $v_i$ to $v_j$ that implies a direct causal relationship from variable $x_i$ onto variable $x_j$. The set of all nodes is denoted by $V$, the set of all edges by $E$, as such, the complete DAG is the tuple $G=(V,E)$. The seminal works of Spirtes and Pearl [@spirtes2000causation;@pearl2009causality] introduce the theory of causal analysis, do-calculus, and how to analyze a DAG to estimate the total or direct causal effect from a variable $x_i$ onto a variable $x_j$. The direct effect is the effect associated with the edge $e_{ij}$ only (if it exists), while the total effect takes indirect effects via other paths from $v_i$ to $v_j$ into account, too. Here we estimated total effects only, since most of our variables were not hypothesized to have a direct effect on the *reported* number of new COVID-19 cases. In contrast to prediction tasks, where one would include all variables available, it is actually ill-advised to use all available variables to estimate causal effects, due to introducing bias by adjusting for unnecessary variables within the causal DAG. This is why we need to identify a valid set of necessary variables (an adjustment set) to estimate the proper causal effect [@pearl2009causality]. The "minimal adjustment set" [@greenland1999causal] is a valid adjustment set of variables that does not contain another valid adjustment set as a subset. However, identifying a minimal adjustment set might not be enough to reliably estimate the causal effect. Thus, we identified the "optimal adjustment set" [@henckel2019graphical] as the set of variables which is a valid adjustment set while having the lowest asymptotic variance in the resulting causal effect estimates. 

We analyzed the DAG from Section \@ref(causal-model) with the R Software [@rsoftware] and the R packages `dagitty` (formal representation of the graph and minimal adjustment sets [@textor_robust_2017]) and `pcalg` (for finding an optimal adjustment set [@pcalg]). For the defined exposures and the outcome "Reported new cases of COVID-19", we computed the minimal and optimal adjustment sets. Since it was possible that these sets contained unobserved variables that needed to be left out of the regression model, we chose the valid set with the highest pseudo-$R^2$ (see next section) to estimate the final total causal effect from exposure to outcome.

## Regression with negative binomial model

We can estimate the causal effect from exposure to outcome by regression [@pearl2009causality]. Since the outcome "Reported new cases of COVID-19" is a count variable, one should not employ a linear regression model with Gaussian errors, but instead we assumed a log-linear relationship between the expected value of the outcome $Y$ (new cases) and regressors $x$, as well as a Poisson or negative binomial distribution for $Y$:
\begin{equation}
\log(\mathbb{E}[Y|x]) = \alpha + \sum_{i\in S}\beta_i\cdot x_{i}, (\#eq:regmodel)
\end{equation}
where $\alpha$ is the regression intercept, $S$ is the set of adjustment variables for the exposure $i^{\ast}$ including the exposure variable itself, $\beta_i$ are the regression coefficients corresponding to the variables $x_i$. As such $\beta_{i^{\ast}}$ is the total causal effect from exposure variable $x_{i^{\ast}}$ on the outcome Y.

The Poisson regression assumes equality of mean and variance. If this is not the case one observes so-called overdispersion (the variance is higher than the mean), this indicates one should use regression with a negative binomial distribution instead to estimate the variance parameter separately from the mean. 

We needed to account for the fact that our outcome is not counted per time unit (one day) only, but depends on the number of active COVID-19 cases: Holding all other variables fixed, the number of new cases $Y$ is a constant proportion of the number of active cases $A$. This was modeled by including an offset $\log(A+1)$ in the regression model \@ref(eq:regmodel):
\begin{align}
\log(\mathbb{E}[Y|x]) &= \alpha + \log(A+1) + \sum_{i\in S}\beta_i\cdot x_{i} \nonumber \\
\Leftrightarrow \log(\frac{\mathbb{E}[Y|x]}{A+1}) &= \alpha + \sum\beta_i\cdot x_{i} (\#eq:logratemodel) \\
\Leftrightarrow \frac{\mathbb{E}[Y|x]}{A+1} &= \exp(\alpha)\cdot \prod \exp(\beta_i)^{x_i}. (\#eq:ratechange)
\end{align}
Here we added a pseudocount "$+1$" to ensure a finite logarithm and avoid division by $0$. 

One can interpret the model as approximating the log-ratio of new cases and active cases by a linear combination of the regressor variables \@ref(eq:logratemodel). If all variables $x_i$ are centered in \@ref(eq:ratechange), we have for the baseline $\forall i\ x_i=0 \Rightarrow \mathbb{E}[Y|x=0]=\exp(\alpha)\cdot (A+1)$. In other words, the exponentiated intercept is the baseline daily infection rate (how many people does one infected individual infect in one day). If we hold all variables $x_i$ fixed (e.g. at baseline 0) in \@ref(eq:ratechange) but now increase the exposure variable $x_{i^{\ast}}=0$ by one unit to $x_{i^{\ast}}+1=0+1$, we have $\mathbb{E}[Y|x']=\exp(\alpha)\cdot(A+1)\exp(\beta_{i^{\ast}}^{x_{i^{\ast}}+1})\prod_{i\neq i^{\ast}}\exp(\beta_i)^0=\exp(\alpha)\cdot(A+1)\exp(\beta_{i^{\ast}})$, which means the exponentiated coefficient $\beta_{i^{\ast}}$ describes the rate change of the outcome by one unit increase of the exposure.

In practice, given observations of $Y$ and $x$ we estimate the regression coefficients $\alpha$ and $\beta_i$  by *maximum likelihood* [@maxlikelihood]. Our observational measurements are $y_{kt}$ and $x_{ikt}$, where $k$ indicates the corresponding district and $t$ the date of measurement.

When we analyzed different adjustment sets given by analysis of the causal DAG (i.e. the minimal and optimal adjustment sets), we first checked if the set included unobserved variables. If this was the case for the optimal adjustment set, we discarded the unobserved variables from the set and checked if it was still a valid adjustment set (function `gac` in package `pcalg` [@perkovi2015complete]). If a minimal adjustment set contained unobserved variables, we discarded the whole set. We conducted a log-linear regression (function `glm` with `family=poisson()` for Poisson regression, and `glm.nb` from the `MASS` package for the negative binomial regression [@mass]) for every remaining valid adjustment set as regressors and calculated a Pseudo-$R^2$ given by $1-V_m/V_0$, where $V_m$ is the sum of squared prediction errors of the current model and $V_0$ is the sum of squared prediction errors of the null model (intercept and offset only). That is, our Pseudo-$R^2$ is $1$ minus the fraction of variance unexplained. Finally, we decided for the model/adjustment set with the highest pseudo-$R^2$. We report the exponentiated estimated coefficients along with 99 percent confidence intervals of the estimates.